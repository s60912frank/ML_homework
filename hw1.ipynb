{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataset: (20640, 8)\n",
      "Shape of label: (20640,)\n",
      "20640\n",
      "========================\n",
      "epoch: 0, \n",
      "Cost: 1424.0803611610067, \n",
      "Weight: [[ 0.00155175 0.00361538 0.00120074 0.00012267 0.00043569 
0.00030819\n",
      " 0.00419649 -0.01462797]], \n",
      "Bias: 0.00012255142792128026\n",
      "========================\n",
      "epoch: 1, \n",
      "Cost: 2911.6431078042765, \n",
      "Weight: [[ 2.68942746e-03 2.61711399e-03 1.71095040e-03 
9.95814189e-05\n",
      " 4.37107490e-04 3.07044451e-04 4.05355636e-03 -1.49901416e-02]], \n",
      "Bias: 0.00012674485333263874\n",
      "========================\n",
      "epoch: 2, \n",
      "Cost: 2923.1320473524306, \n",
      "Weight: [[ 3.81742325e-03 1.68834184e-03 2.20704614e-03 
7.40848482e-05\n",
      " 4.35916503e-04 3.07144946e-04 3.86846135e-03 -1.52115934e-02]], \n",
      "Bias: 0.00012975442223250866\n",
      "========================\n",
      "epoch: 3, \n",
      "Cost: 2919.8164785787317, \n",
      "Weight: [[ 4.93929861e-03 8.56633356e-04 2.69504404e-03 
4.74486114e-05\n",
      " 4.34765330e-04 3.10072297e-04 3.67719657e-03 -1.54109132e-02]], \n",
      "Bias: 0.00013256607053335756\n",
      "========================\n",
      "epoch: 4, \n",
      "Cost: 2915.9934509890604, \n",
      "Weight: [[ 6.05534436e-03 1.12418165e-04 3.17539577e-03 
1.97590198e-05\n",
      " 4.33668727e-04 3.15044279e-04 3.48072592e-03 -1.55911800e-02]], \n",
      "Bias: 0.00013520360516849905\n",
      "========================\n",
      "epoch: 5, \n",
      "Cost: 2911.8217821144244, \n",
      "Weight: [[ 7.16570904e-03 -5.53191523e-04 3.64848250e-03 
-8.91409763e-06\n",
      " 4.32621804e-04 3.21402913e-04 3.27960332e-03 -1.57543663e-02]], \n",
      "Bias: 0.00013768833014182746\n",
      "========================\n",
      "epoch: 6, \n",
      "Cost: 2907.291686853836, \n",
      "Weight: [[ 8.27062316e-03 -1.14816416e-03 4.11462737e-03 
-3.85081476e-05\n",
      " 4.31620021e-04 3.28621711e-04 3.07436218e-03 -1.59022789e-02]], \n",
      "Bias: 0.00014003289106767625\n",
      "========================\n",
      "epoch: 7, \n",
      "Cost: 2902.4748588897805, \n",
      "Weight: [[ 9.37019009e-03 -1.67969731e-03 4.57415404e-03 
-6.89662993e-05\n",
      " 4.30656946e-04 3.36271885e-04 2.86545279e-03 -1.60363279e-02]], \n",
      "Bias: 0.00014225284394342452\n",
      "========================\n",
      "epoch: 8, \n",
      "Cost: 2897.4053384832155, \n",
      "Weight: [[ 0.01046464 -0.00215424 0.00502733 -0.00010024 0.00042973 
0.00034401\n",
      " 0.00265328 -0.01615818]], \n",
      "Bias: 0.00014435930643230677\n",
      "========================\n",
      "epoch: 9, \n",
      "Cost: 2892.0572298987327, \n",
      "Weight: [[ 0.0115541 -0.00257754 0.00547438 -0.00013227 0.00042884 
0.00035158\n",
      " 0.00243828 -0.01626883]], \n",
      "Bias: 0.0001463648077333346\n",
      "========================\n",
      "epoch: 10, \n",
      "Cost: 2886.5132273232407, \n",
      "Weight: [[ 0.01263868 -0.00295479 0.00591558 -0.00016503 0.00042798 
0.00035877\n",
      " 0.00222072 -0.01636959]], \n",
      "Bias: 0.00014828017447143793\n",
      "========================\n",
      "epoch: 11, \n",
      "Cost: 2880.769836885363, \n",
      "Weight: [[ 0.01371848 -0.00329072 0.00635111 -0.00019848 0.00042714 
0.00036543\n",
      " 0.00200093 -0.01646149]], \n",
      "Bias: 0.0001501120423199609\n",
      "========================\n",
      "epoch: 12, \n",
      "Cost: 2874.838484404154, \n",
      "Weight: [[ 0.01479369 -0.0035895 0.00678117 -0.00023257 0.00042633 
0.00037144\n",
      " 0.00177919 -0.01654541]], \n",
      "Bias: 0.0001518689387012273\n",
      "========================\n",
      "epoch: 13, \n",
      "Cost: 2868.7591812854444, \n",
      "Weight: [[ 0.01586431 -0.0038549 0.00720594 -0.00026729 0.00042554 
0.00037672\n",
      " 0.00155571 -0.01662212]], \n",
      "Bias: 0.00015356008952949196\n",
      "========================\n",
      "epoch: 14, \n",
      "Cost: 2862.5452146797807, \n",
      "Weight: [[ 0.01693046 -0.00409025 0.00762562 -0.00030259 0.00042477 
0.00038122\n",
      " 0.00133069 -0.01669247]], \n",
      "Bias: 0.00015519134467467666\n",
      "========================\n",
      "epoch: 15, \n",
      "Cost: 2856.2281602338967, \n",
      "Weight: [[ 0.01799222 -0.00429868 0.0080403 -0.00033846 0.00042402 
0.00038491\n",
      " 0.00110439 -0.01675705]], \n",
      "Bias: 0.00015676734619773924\n",
      "========================\n",
      "epoch: 16, \n",
      "Cost: 2849.770650132884, \n",
      "Weight: [[ 0.01904967 -0.00448289 0.00845014 -0.00037486 0.00042328 
0.00038777\n",
      " 0.00087696 -0.01681648]], \n",
      "Bias: 0.00015829407493583858\n",
      "========================\n",
      "epoch: 17, \n",
      "Cost: 2843.2324104551376, \n",
      "Weight: [[ 0.02010297 -0.00464533 0.0088552 -0.00041177 0.00042256 
0.00038981\n",
      " 0.00064857 -0.01687129]], \n",
      "Bias: 0.00015977835573721677\n",
      "========================\n",
      "epoch: 18, \n",
      "Cost: 2836.65732117624, \n",
      "Weight: [[ 0.0211521 -0.00478826 0.00925567 -0.00044918 0.00042185 
0.00039104\n",
      " 0.00041933 -0.01692201]], \n",
      "Bias: 0.00016122183296829462\n",
      "========================\n",
      "epoch: 19, \n",
      "Cost: 2829.9783549127396, \n",
      "Weight: [[ 0.02219706 -0.00491361 0.00965163 -0.00048707 0.00042116 
0.00039148\n",
      " 0.00018939 -0.01696898]], \n",
      "Bias: 0.00016262994904536754\n",
      "========================\n",
      "epoch: 20, \n",
      "Cost: 2823.268248611971, \n",
      "Weight: [[ 2.32379530e-02 -5.02321357e-03 1.00432681e-02 
-5.25419659e-04\n",
      " 4.20478347e-04 3.91159381e-04 -4.11363981e-05 -1.70127489e-02]], \n",
      "Bias: 0.00016400573076680303\n",
      "========================\n",
      "epoch: 21, \n",
      "Cost: 2816.4496488742375, \n",
      "Weight: [[ 0.02427476 -0.00511864 0.01043057 -0.00056421 0.00041981 
0.00039011\n",
      " -0.00027216 -0.01705355]], \n",
      "Bias: 0.00016535187023691833\n",
      "========================\n",
      "epoch: 22, \n",
      "Cost: 2809.653315024809, \n",
      "Weight: [[ 0.02530756 -0.0052013 0.01081364 -0.00060343 0.00041915 
0.00038836\n",
      " -0.00050356 -0.01709167]], \n",
      "Bias: 0.00016667204909026623\n",
      "========================\n",
      "epoch: 23, \n",
      "Cost: 2802.808443767995, \n",
      "Weight: [[ 0.02633649 -0.00527253 0.01119258 -0.00064306 0.00041849 
0.00038595\n",
      " -0.00073525 -0.01712745]], \n",
      "Bias: 0.00016796842101030052\n",
      "========================\n",
      "epoch: 24, \n",
      "Cost: 2795.9486040577603, \n",
      "Weight: [[ 0.02736156 -0.00533354 0.01156741 -0.00068309 0.00041785 
0.00038292\n",
      " -0.00096719 -0.01716121]], \n",
      "Bias: 0.0001692438090685755\n",
      "========================\n",
      "epoch: 25, \n",
      "Cost: 2789.0890154423705, \n",
      "Weight: [[ 0.02838285 -0.00538536 0.01193827 -0.00072351 0.00041722 
0.0003793\n",
      " -0.00119933 -0.01719311]], \n",
      "Bias: 0.00017049728194251657\n",
      "========================\n",
      "epoch: 26, \n",
      "Cost: 2782.1889474430827, \n",
      "Weight: [[ 0.02940019 -0.00542888 0.01230509 -0.00076432 0.00041659 
0.00037514\n",
      " -0.00143159 -0.01722335]], \n",
      "Bias: 0.00017173275409732014\n",
      "========================\n",
      "epoch: 27, \n",
      "Cost: 2775.2906465420324, \n",
      "Weight: [[ 0.03041383 -0.005465 0.01266814 -0.00080549 0.00041597 
0.00037047\n",
      " -0.00166386 -0.017252 ]], \n",
      "Bias: 0.00017295258294325322\n",
      "========================\n",
      "epoch: 28, \n",
      "Cost: 2768.382721035634, \n",
      "Weight: [[ 0.03142383 -0.00549445 0.01302734 -0.00084702 0.00041535 
0.00036533\n",
      " -0.00189615 -0.01727946]], \n",
      "Bias: 0.0001741577871143818\n",
      "========================\n",
      "epoch: 29, \n",
      "Cost: 2761.483017207614, \n",
      "Weight: [[ 0.03243006 -0.00551794 0.01338266 -0.00088891 0.00041474 
0.00035975\n",
      " -0.00212839 -0.01730575]], \n",
      "Bias: 0.00017535120423417538\n",
      "========================\n",
      "epoch: 30, \n",
      "Cost: 2754.610195666521, \n",
      "Weight: [[ 0.03343258 -0.00553609 0.01373438 -0.00093114 0.00041414 
0.00035376\n",
      " -0.00236058 -0.017331 ]], \n",
      "Bias: 0.0001765316555975005\n",
      "========================\n",
      "epoch: 31, \n",
      "Cost: 2747.706884545171, \n",
      "Weight: [[ 0.03443142 -0.00554939 0.01408248 -0.0009737 0.00041354 
0.00034741\n",
      " -0.00259263 -0.0173554 ]], \n",
      "Bias: 0.00017770030535757542\n",
      "========================\n",
      "epoch: 32, \n",
      "Cost: 2740.842908971827, \n",
      "Weight: [[ 0.03542681 -0.00555842 0.01442686 -0.00101659 0.00041295 
0.00034072\n",
      " -0.00282454 -0.01737894]], \n",
      "Bias: 0.00017885853594634682\n",
      "========================\n",
      "epoch: 33, \n",
      "Cost: 2734.007833821893, \n",
      "Weight: [[ 0.03641869 -0.00556357 0.01476771 -0.0010598 0.00041236 
0.00033372\n",
      " -0.00305626 -0.01740184]], \n",
      "Bias: 0.00018000819545704871\n",
      "========================\n",
      "epoch: 34, \n",
      "Cost: 2727.186807982038, \n",
      "Weight: [[ 0.03740684 -0.00556529 0.01510502 -0.00110333 0.00041178 
0.00032643\n",
      " -0.00328779 -0.01742405]], \n",
      "Bias: 0.00018114915292244405\n",
      "========================\n",
      "epoch: 35, \n",
      "Cost: 2720.3833039140754, \n",
      "Weight: [[ 0.03839158 -0.00556394 0.01543883 -0.00114716 0.0004112 
0.00031888\n",
      " -0.0035191 -0.0174458 ]], \n",
      "Bias: 0.00018228321278002113\n",
      "========================\n",
      "epoch: 36, \n",
      "Cost: 2713.596055152509, \n",
      "Weight: [[ 0.03937265 -0.00555983 0.01576914 -0.0011913 0.00041063 
0.0003111\n",
      " -0.00375019 -0.01746715]], \n",
      "Bias: 0.00018340990936849266\n",
      "========================\n",
      "epoch: 37, \n",
      "Cost: 2706.8398807695708, \n",
      "Weight: [[ 0.0403501 -0.00555323 0.01609617 -0.00123573 0.00041006 
0.0003031\n",
      " -0.00398103 -0.01748805]], \n",
      "Bias: 0.0001845290680648759\n",
      "========================\n",
      "epoch: 38, \n",
      "Cost: 2700.1325338063043, \n",
      "Weight: [[ 0.04132408 -0.00554447 0.01641971 -0.00128045 0.00040949 
0.00029491\n",
      " -0.00421163 -0.01750862]], \n",
      "Bias: 0.0001856408780440688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================\n",
      "epoch: 39, \n",
      "Cost: 2693.4003303468553, \n",
      "Weight: [[ 0.04229452 -0.00553372 0.01673984 -0.00132544 0.00040893 
0.00028655\n",
      " -0.0044419 -0.01752888]], \n",
      "Bias: 0.000186748628038913\n",
      "========================\n",
      "epoch: 40, \n",
      "Cost: 2686.746534865266, \n",
      "Weight: [[ 0.04326149 -0.00552128 0.01705669 -0.00137073 0.00040837 
0.00027803\n",
      " -0.00467189 -0.0175489 ]], \n",
      "Bias: 0.00018785128486342728\n",
      "========================\n",
      "epoch: 41, \n",
      "Cost: 2680.085067700254, \n",
      "Weight: [[ 0.04422505 -0.00550722 0.01737043 -0.00141628 0.00040782 
0.00026938\n",
      " -0.00490149 -0.01756873]], \n",
      "Bias: 0.0001889495615614578\n",
      "========================\n",
      "epoch: 42, \n",
      "Cost: 2673.4759193929167, \n",
      "Weight: [[ 0.04518524 -0.00549178 0.01768089 -0.00146211 0.00040726 
0.0002606\n",
      " -0.0051308 -0.01758839]], \n",
      "Bias: 0.00019004274508915842\n",
      "========================\n",
      "epoch: 43, \n",
      "Cost: 2666.8954941099973, \n",
      "Weight: [[ 0.046142 -0.00547513 0.01798817 -0.00150821 0.00040671 
0.00025171\n",
      " -0.00535981 -0.01760798]], \n",
      "Bias: 0.00019113192684017122\n",
      "========================\n",
      "epoch: 44, \n",
      "Cost: 2660.336825781669, \n",
      "Weight: [[ 0.04709539 -0.00545734 0.01829222 -0.00155456 0.00040617 
0.00024272\n",
      " -0.00558843 -0.01762737]], \n",
      "Bias: 0.00019221809634473175\n",
      "========================\n",
      "epoch: 45, \n",
      "Cost: 2653.819299927801, \n",
      "Weight: [[ 0.04804539 -0.00543861 0.01859307 -0.00160117 0.00040563 
0.00023365\n",
      " -0.00581669 -0.01764669]], \n",
      "Bias: 0.00019330024952068925\n",
      "========================\n",
      "epoch: 46, \n",
      "Cost: 2647.3524716775596, \n",
      "Weight: [[ 0.04899214 -0.00541901 0.0188908 -0.00164804 0.00040509 
0.00022451\n",
      " -0.00604461 -0.017666 ]], \n",
      "Bias: 0.00019437959417700768\n",
      "========================\n",
      "epoch: 47, \n",
      "Cost: 2640.91310364106, \n",
      "Weight: [[ 0.04993526 -0.00539871 0.01918545 -0.00169515 0.00040455 
0.00021529\n",
      " -0.00627219 -0.0176853 ]], \n",
      "Bias: 0.00019545224495232105\n",
      "========================\n",
      "epoch: 48, \n",
      "Cost: 2634.5222776289197, \n",
      "Weight: [[ 0.05087521 -0.0053778 0.01947708 -0.00174251 0.00040402 
0.00020603\n",
      " -0.00649943 -0.01770462]], \n",
      "Bias: 0.00019652352784760296\n",
      "========================\n",
      "epoch: 49, \n",
      "Cost: 2628.097176935593, \n",
      "Weight: [[ 0.05181222 -0.00535622 0.01976572 -0.00179011 0.00040349 
0.00019672\n",
      " -0.00672624 -0.01772378]], \n",
      "Bias: 0.00019759235146921128\n",
      "========================\n",
      "epoch: 50, \n",
      "Cost: 2621.774661313188, \n",
      "Weight: [[ 0.05274614 -0.00533417 0.02005135 -0.00183794 0.00040296 
0.00018736\n",
      " -0.0069527 -0.01774309]], \n",
      "Bias: 0.00019865854119416326\n",
      "========================\n",
      "epoch: 51, \n",
      "Cost: 2615.447757042025, \n",
      "Weight: [[ 0.0536767 -0.00531163 0.0203341 -0.00188601 0.00040243 
0.00017798\n",
      " -0.00717877 -0.01776237]], \n",
      "Bias: 0.00019971959409303963\n",
      "========================\n",
      "epoch: 52, \n",
      "Cost: 2609.1436870420607, \n",
      "Weight: [[ 0.05460379 -0.00528875 0.0206138 -0.00193432 0.00040191 
0.00016856\n",
      " -0.00740446 -0.0177817 ]], \n",
      "Bias: 0.00020078029774595052\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np \n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from IPython.display import clear_output, Image, display, HTML\n",
    "\n",
    "###### Do not modify here ###### \n",
    "def strip_consts(graph_def, max_const_size=32):\n",
    " \"\"\"Strip large constant values from graph_def.\"\"\"\n",
    " strip_def = tf.GraphDef()\n",
    " for n0 in graph_def.node:\n",
    " n = strip_def.node.add() \n",
    " n.MergeFrom(n0)\n",
    " if n.op == 'Const':\n",
    " tensor = n.attr['value'].tensor\n",
    " size = len(tensor.tensor_content)\n",
    " if size > max_const_size:\n",
    " tensor.tensor_content = \"<stripped %d bytes>\"%size\n",
    " return strip_def\n",
    "\n",
    "def show_graph(graph_def, max_const_size=32):\n",
    " \"\"\"Visualize TensorFlow graph.\"\"\"\n",
    " if hasattr(graph_def, 'as_graph_def'):\n",
    " graph_def = graph_def.as_graph_def()\n",
    " strip_def = graph_def\n",
    " #strip_def = strip_consts(graph_def, max_const_size=max_const_size)\n",
    " code = \"\"\"\n",
    " <script>\n",
    " function load() {{\n",
    " document.getElementById(\"{id}\").pbtxt = {data};\n",
    " }}\n",
    " </script>\n",
    " <link rel=\"import\" 
href=\"https://tensorboard.appspot.com/tf-graph-basic.build.html\" 
onload=load()>\n",
    " <div style=\"height:600px\">\n",
    " <tf-graph-basic id=\"{id}\"></tf-graph-basic>\n",
    " </div>\n",
    " \"\"\".format(data=repr(str(strip_def)), 
id='graph'+str(np.random.rand()))\n",
    "\n",
    " iframe = \"\"\"\n",
    " <iframe seamless style=\"width:1200px;height:620px;border:0\" 
srcdoc=\"{}\"></iframe>\n",
    " \"\"\".format(code.replace('\"', '&quot;'))\n",
    " display(HTML(iframe))\n",
    "###### Do not modify here ######\n",
    "\n",
    "###### Implement Data Preprocess here ######\n",
    "housing = fetch_california_housing()\n",
    "print(\"Shape of dataset:\", housing.data.shape)\n",
    "print(\"Shape of label:\", housing.target.shape)\n",
    "\n",
    "###### Constants ######\n",
    "LEARNING_RATE = 0.00000003\n",
    "#BATCH_SIZE = 100\n",
    "DATA_LENGTH = len(housing.data)\n",
    "print(DATA_LENGTH)\n",
    "\n",
    "\"\"\"\n",
    "# make batch here\n",
    "def make_batch(x, y_hat):\n",
    " #global BATCH_SIZE \n",
    " batch_collection = []\n",
    " one_batch = np.zeros((BATCH_SIZE, 8))\n",
    " output_collection = []\n",
    " one_output = []\n",
    " counter = 0\n",
    " for d in range(DATA_LENGTH):\n",
    " if counter < BATCH_SIZE:\n",
    " one_batch[counter] = x[d]\n",
    " counter++\n",
    " one_output.append(y_hat[d])\n",
    " else:\n",
    " batch_collection.append(one_batch)\n",
    " output_collection.append(one_output)\n",
    " #重新init\n",
    " one_batch = np.zeros((BATCH_SIZE, 8))\n",
    " one_batch[0] = x[d]\n",
    " counter = 1\n",
    " one_output = [y_hat[d]]\n",
    " #最後把不足batch的也放進去\n",
    " if(len(one_batch) > 0):\n",
    " batch_collection.append(one_batch)\n",
    " output_collection.append(one_output)\n",
    " return batch_collection, output_collection\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "###### Implement Data Preprocess here ######\n",
    "X = tf.placeholder(tf.float32, shape=(1, 8), name=\"X\")\n",
    "Y = tf.placeholder(tf.float32, name=\"Y\")\n",
    "#w = tf.Variable(np.random.rand(8, 1).astype('f'), name=\"weights\")\n",
    "w = tf.Variable(np.zeros((8, 1)).astype('f'), name=\"weights\")\n",
    "b = tf.Variable(0.0, name=\"bias\")\n",
    "\n",
    "Y_hat = tf.add(tf.matmul(X, w), b)\n",
    "loss = tf.square(Y - Y_hat, name=\"loss\")\n",
    "optimizer = 
tf.train.GradientDescentOptimizer(learning_rate=LEARNING_RATE).minimize(loss)\n",
    "\n",
    "###### Start TF session ######\n",
    "with tf.Session() as sess:\n",
    " sess.run(tf.global_variables_initializer())\n",
    " #x_bat, y_bat = make_batch(housing.data, housing.target)\n",
    " for i in range(100):\n",
    " cost = 0\n",
    " for j in range(DATA_LENGTH): #要改\n",
    " x = housing.data[j].reshape((1, 8))\n",
    " y = housing.target[j]\n",
    " sess.run(optimizer, feed_dict={X: x, Y: y}) #actual training\n",
    " cost += sess.run(loss, feed_dict={X: x, Y: y})[0][0]\n",
    " print(\"========================\\nepoch: {0}, \\nCost: {1}, \\nWeight: 
{2}, \\nBias: {3}\".format(i, cost / DATA_LENGTH, sess.run(w).reshape((1, 
8)), sess.run(b)))\n",
    " show_graph(tf.get_default_graph().as_graph_def())\n",
    "###### Start TF session ######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
